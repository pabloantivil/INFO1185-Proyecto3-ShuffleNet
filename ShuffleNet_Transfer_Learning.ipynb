{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f499968",
   "metadata": {},
   "source": [
    "# üöÄ Proyecto ShuffleNet - Transfer Learning\n",
    "## INFO1185 - Inteligencia Artificial III\n",
    "### Clasificaci√≥n de Vegetales con ShuffleNet V2\n",
    "\n",
    "**Autor:** Benja  \n",
    "**A√±o:** 2025\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Descripci√≥n del Proyecto\n",
    "\n",
    "Este proyecto implementa Transfer Learning usando **ShuffleNet V2** preentrenado en ImageNet para clasificar **5 tipos de vegetales**:\n",
    "\n",
    "1. üå∂Ô∏è Jalape√±o\n",
    "2. üå∂Ô∏è Chili Pepper\n",
    "3. ü•ï Carrot\n",
    "4. üåΩ Corn\n",
    "5. ü•í Cucumber\n",
    "\n",
    "### Caracter√≠sticas Principales:\n",
    "- ‚úÖ Modelo base: ShuffleNet V2 x1.0 (preentrenado en ImageNet)\n",
    "- ‚úÖ Feature extractor congelado\n",
    "- ‚úÖ Clasificador simple (1 capa FC)\n",
    "- ‚úÖ Dataset dividido en train/val/test\n",
    "- ‚úÖ Data augmentation en entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52691ae8",
   "metadata": {},
   "source": [
    "## üì¶ Paso 1: Instalaci√≥n de Dependencias\n",
    "\n",
    "**Nota:** Si est√°s en Google Colab, ejecuta esta celda. Si ya tienes las librer√≠as instaladas, puedes saltarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c19f2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as instaladas correctamente!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Instalaci√≥n de paquetes necesarios\n",
    "!pip install torch torchvision tqdm matplotlib numpy pillow -q\n",
    "\n",
    "print(\"‚úÖ Librer√≠as instaladas correctamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd0e118",
   "metadata": {},
   "source": [
    "## üìö Paso 2: Importar Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4762807d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PyTorch version: 2.9.1+cpu\n",
      "‚úÖ Torchvision version: 2.9.1+cpu\n",
      "‚úÖ CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"‚úÖ PyTorch version:\", torch.__version__)\n",
    "print(\"‚úÖ Torchvision version:\", torch.__version__)\n",
    "print(\"‚úÖ CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f202b15",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Paso 3: Clase de Preparaci√≥n de Datos\n",
    "\n",
    "Esta clase maneja:\n",
    "- Carga del dataset\n",
    "- Filtrado de las 5 clases espec√≠ficas\n",
    "- Transformaciones (data augmentation para train, normalizaci√≥n para val/test)\n",
    "- Creaci√≥n de DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76213d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Clase DataPreparation definida!\n"
     ]
    }
   ],
   "source": [
    "class DataPreparation:\n",
    "    \"\"\"\n",
    "    Clase para preparar y cargar el dataset.\n",
    "    Filtra 5 clases espec√≠ficas: jalepeno, chilli pepper, carrot, corn, cucumber.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir=\"./archive\", batch_size=32):\n",
    "        \"\"\"\n",
    "        Inicializa el preparador de datos.\n",
    "        \n",
    "        Args:\n",
    "            data_dir (str): Directorio ra√≠z del dataset (default: ./archive)\n",
    "            batch_size (int): Tama√±o del batch para los DataLoaders\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Las 5 clases que necesitamos\n",
    "        self.selected_classes = [\n",
    "            'jalepeno',\n",
    "            'chilli pepper',\n",
    "            'carrot',\n",
    "            'corn',\n",
    "            'cucumber'\n",
    "        ]\n",
    "        \n",
    "        # Rutas de train, val y test\n",
    "        self.train_dir = os.path.join(data_dir, 'train')\n",
    "        self.val_dir = os.path.join(data_dir, 'validation')\n",
    "        self.test_dir = os.path.join(data_dir, 'test')\n",
    "    \n",
    "    def get_train_transforms(self):\n",
    "        \"\"\"\n",
    "        Transformaciones para entrenamiento con data augmentation.\n",
    "        \"\"\"\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.2,\n",
    "                contrast=0.2,\n",
    "                saturation=0.2,\n",
    "                hue=0.1\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "    def get_val_test_transforms(self):\n",
    "        \"\"\"\n",
    "        Transformaciones para validaci√≥n y test sin augmentation.\n",
    "        \"\"\"\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "    def create_filtered_dataset(self, dataset):\n",
    "        \"\"\"\n",
    "        Crea un dataset filtrado con labels remapeados de 0 a 4.\n",
    "        \n",
    "        Args:\n",
    "            dataset: Dataset original de PyTorch\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (samples filtrados, mapeo de labels)\n",
    "        \"\"\"\n",
    "        class_to_idx = dataset.class_to_idx\n",
    "        \n",
    "        # Obtener √≠ndices originales de las clases seleccionadas\n",
    "        selected_indices = {class_to_idx[cls]: i for i, cls in enumerate(self.selected_classes) if cls in class_to_idx}\n",
    "        \n",
    "        # Filtrar samples y remapear labels\n",
    "        filtered_samples = []\n",
    "        for path, label in dataset.samples:\n",
    "            if label in selected_indices:\n",
    "                new_label = selected_indices[label]  # Remapear a 0-4\n",
    "                filtered_samples.append((path, new_label))\n",
    "        \n",
    "        return filtered_samples\n",
    "    \n",
    "    def create_dataloaders(self):\n",
    "        \"\"\"\n",
    "        Crea los DataLoaders para train, validation y test.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (train_loader, val_loader, test_loader, num_classes, class_names)\n",
    "        \"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(\"üì¶ PREPARANDO DATOS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Crear datasets completos (sin transformaciones primero para filtrar)\n",
    "        train_dataset_full = datasets.ImageFolder(root=self.train_dir)\n",
    "        val_dataset_full = datasets.ImageFolder(root=self.val_dir)\n",
    "        test_dataset_full = datasets.ImageFolder(root=self.test_dir)\n",
    "        \n",
    "        print(f\"\\nüìä Dataset completo:\")\n",
    "        print(f\"   - Total de clases: {len(train_dataset_full.classes)}\")\n",
    "        print(f\"   - Train: {len(train_dataset_full)} im√°genes\")\n",
    "        print(f\"   - Val: {len(val_dataset_full)} im√°genes\")\n",
    "        print(f\"   - Test: {len(test_dataset_full)} im√°genes\")\n",
    "        \n",
    "        # Filtrar y remapear labels\n",
    "        print(f\"\\nüîç Filtrando solo las 5 clases requeridas...\")\n",
    "        train_samples = self.create_filtered_dataset(train_dataset_full)\n",
    "        val_samples = self.create_filtered_dataset(val_dataset_full)\n",
    "        test_samples = self.create_filtered_dataset(test_dataset_full)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Dataset filtrado (5 clases):\")\n",
    "        print(f\"   - Clases: {self.selected_classes}\")\n",
    "        print(f\"   - Train: {len(train_samples)} im√°genes\")\n",
    "        print(f\"   - Val: {len(val_samples)} im√°genes\")\n",
    "        print(f\"   - Test: {len(test_samples)} im√°genes\")\n",
    "        \n",
    "        # Crear datasets con transformaciones y samples filtrados\n",
    "        train_dataset = datasets.ImageFolder(root=self.train_dir, transform=self.get_train_transforms())\n",
    "        train_dataset.samples = train_samples\n",
    "        train_dataset.imgs = train_samples\n",
    "        train_dataset.targets = [s[1] for s in train_samples]\n",
    "        \n",
    "        val_dataset = datasets.ImageFolder(root=self.val_dir, transform=self.get_val_test_transforms())\n",
    "        val_dataset.samples = val_samples\n",
    "        val_dataset.imgs = val_samples\n",
    "        val_dataset.targets = [s[1] for s in val_samples]\n",
    "        \n",
    "        test_dataset = datasets.ImageFolder(root=self.test_dir, transform=self.get_val_test_transforms())\n",
    "        test_dataset.samples = test_samples\n",
    "        test_dataset.imgs = test_samples\n",
    "        test_dataset.targets = [s[1] for s in test_samples]\n",
    "        \n",
    "        # Crear DataLoaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüì¶ DataLoaders creados:\")\n",
    "        print(f\"   - Batch size: {self.batch_size}\")\n",
    "        print(f\"   - Train batches: {len(train_loader)}\")\n",
    "        print(f\"   - Val batches: {len(val_loader)}\")\n",
    "        print(f\"   - Test batches: {len(test_loader)}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        return train_loader, val_loader, test_loader, 5, self.selected_classes\n",
    "\n",
    "print(\"‚úÖ Clase DataPreparation definida!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9159cd10",
   "metadata": {},
   "source": [
    "## ü§ñ Paso 4: Definici√≥n del Modelo ShuffleNet\n",
    "\n",
    "Clase que implementa:\n",
    "- Carga de ShuffleNet V2 preentrenado en ImageNet\n",
    "- Congelamiento del feature extractor\n",
    "- Clasificador simple (1 capa FC, sin BatchNorm, sin Dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc2eb1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Clase ShuffleNetSimple definida!\n"
     ]
    }
   ],
   "source": [
    "class ShuffleNetSimple(nn.Module):\n",
    "    \"\"\"\n",
    "    ShuffleNet con clasificador simple (Versi√≥n 1).\n",
    "    \n",
    "    Caracter√≠sticas:\n",
    "    - Modelo base: ShuffleNet V2 preentrenado en ImageNet\n",
    "    - Clasificador: Una sola capa Fully Connected\n",
    "    - SIN BatchNorm\n",
    "    - SIN Dropout\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=5, pretrained=True, freeze_features=True):\n",
    "        \"\"\"\n",
    "        Inicializa el modelo ShuffleNet con clasificador simple.\n",
    "        \n",
    "        Args:\n",
    "            num_classes (int): N√∫mero de clases de salida (default: 5)\n",
    "            pretrained (bool): Si cargar pesos preentrenados de ImageNet (default: True)\n",
    "            freeze_features (bool): Si congelar las capas convolucionales (default: True)\n",
    "        \"\"\"\n",
    "        super(ShuffleNetSimple, self).__init__()\n",
    "        \n",
    "        # Cargar ShuffleNet V2 preentrenado en ImageNet\n",
    "        print(\"üîÑ Cargando ShuffleNet V2 preentrenado...\")\n",
    "        \n",
    "        # Usar weights parameter (nuevo API de torchvision >= 0.13)\n",
    "        try:\n",
    "            if pretrained:\n",
    "                self.shufflenet = models.shufflenet_v2_x1_0(\n",
    "                    weights=models.ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1\n",
    "                )\n",
    "            else:\n",
    "                self.shufflenet = models.shufflenet_v2_x1_0(weights=None)\n",
    "        except:\n",
    "            # Fallback para versiones antiguas de torchvision\n",
    "            self.shufflenet = models.shufflenet_v2_x1_0(pretrained=pretrained)\n",
    "        \n",
    "        print(\"‚úÖ ShuffleNet V2 cargado exitosamente!\")\n",
    "        \n",
    "        # Congelar o no las capas convolucionales (feature extractor)\n",
    "        if freeze_features:\n",
    "            print(\"‚ùÑÔ∏è  Congelando capas convolucionales (feature extractor)...\")\n",
    "            for param in self.shufflenet.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(\"‚úÖ Capas convolucionales congeladas!\")\n",
    "        else:\n",
    "            print(\"üî• Capas convolucionales entrenable (fine-tuning completo)\")\n",
    "        \n",
    "        # Obtener el tama√±o de entrada del clasificador original\n",
    "        # En ShuffleNet V2 x1.0, la √∫ltima capa conv produce 1024 features\n",
    "        in_features = self.shufflenet.fc.in_features\n",
    "        \n",
    "        # üéØ VERSI√ìN 1: CLASIFICADOR SIMPLE\n",
    "        # Solo una capa Fully Connected\n",
    "        # SIN BatchNorm\n",
    "        # SIN Dropout\n",
    "        self.shufflenet.fc = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "        print(f\"\\nüéØ CLASIFICADOR SIMPLE (Versi√≥n 1) creado:\")\n",
    "        print(f\"   - Input features: {in_features}\")\n",
    "        print(f\"   - Output classes: {num_classes}\")\n",
    "        print(f\"   - Capas: 1 Linear\")\n",
    "        print(f\"   - BatchNorm: NO\")\n",
    "        print(f\"   - Dropout: NO\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass del modelo.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Tensor de entrada [batch_size, 3, 224, 224]\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Logits de salida [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        return self.shufflenet(x)\n",
    "    \n",
    "    def get_trainable_params(self):\n",
    "        \"\"\"\n",
    "        Obtiene los par√°metros entrenables del modelo.\n",
    "        \n",
    "        Returns:\n",
    "            list: Lista de par√°metros que requieren gradiente\n",
    "        \"\"\"\n",
    "        return [p for p in self.parameters() if p.requires_grad]\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Cuenta los par√°metros del modelo.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Diccionario con total, entrenables y congelados\n",
    "        \"\"\"\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        frozen_params = total_params - trainable_params\n",
    "        \n",
    "        return {\n",
    "            'total': total_params,\n",
    "            'trainable': trainable_params,\n",
    "            'frozen': frozen_params\n",
    "        }\n",
    "    \n",
    "    def print_model_info(self):\n",
    "        \"\"\"\n",
    "        Imprime informaci√≥n detallada del modelo.\n",
    "        \"\"\"\n",
    "        params = self.count_parameters()\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üìä INFORMACI√ìN DEL MODELO\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Par√°metros totales:      {params['total']:,}\")\n",
    "        print(f\"Par√°metros entrenables:  {params['trainable']:,}\")\n",
    "        print(f\"Par√°metros congelados:   {params['frozen']:,}\")\n",
    "        print(f\"Porcentaje entrenable:   {params['trainable']/params['total']*100:.2f}%\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "print(\"‚úÖ Clase ShuffleNetSimple definida!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9fbf2e",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Paso 5: Configuraci√≥n de Par√°metros\n",
    "\n",
    "Definimos todos los hiperpar√°metros del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09112bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìã CONFIGURACI√ìN DEL PROYECTO\n",
      "======================================================================\n",
      "‚úÖ Dispositivo: cpu\n",
      "‚úÖ Clases: 5\n",
      "‚úÖ Batch size: 32\n",
      "‚úÖ Learning rate: 0.001\n",
      "‚úÖ √âpocas: 10\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# CONFIGURACI√ìN\n",
    "# ==========================================\n",
    "\n",
    "# Ruta del dataset\n",
    "DATA_DIR = \"./archive\"  # Cambiar si es necesario\n",
    "\n",
    "# Par√°metros del modelo\n",
    "NUM_CLASSES = 5  # jalepeno, chilli pepper, carrot, corn, cucumber\n",
    "\n",
    "# Hiperpar√°metros de entrenamiento\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Dispositivo (GPU si est√° disponible, sino CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìã CONFIGURACI√ìN DEL PROYECTO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"‚úÖ Dispositivo: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"‚úÖ Clases: {NUM_CLASSES}\")\n",
    "print(f\"‚úÖ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"‚úÖ Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"‚úÖ √âpocas: {NUM_EPOCHS}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85172d2",
   "metadata": {},
   "source": [
    "## üì• Paso 6: Cargar Datos\n",
    "\n",
    "Creamos los DataLoaders para entrenamiento, validaci√≥n y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2db4b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üì¶ PREPARANDO DATOS\n",
      "======================================================================\n",
      "\n",
      "üìä Dataset completo:\n",
      "   - Total de clases: 36\n",
      "   - Train: 3115 im√°genes\n",
      "   - Val: 351 im√°genes\n",
      "   - Test: 359 im√°genes\n",
      "\n",
      "üîç Filtrando solo las 5 clases requeridas...\n",
      "\n",
      "‚úÖ Dataset filtrado (5 clases):\n",
      "   - Clases: ['jalepeno', 'chilli pepper', 'carrot', 'corn', 'cucumber']\n",
      "   - Train: 438 im√°genes\n",
      "   - Val: 47 im√°genes\n",
      "   - Test: 50 im√°genes\n",
      "\n",
      "üì¶ DataLoaders creados:\n",
      "   - Batch size: 32\n",
      "   - Train batches: 14\n",
      "   - Val batches: 2\n",
      "   - Test batches: 2\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Datos cargados exitosamente!\n",
      "   Clases: ['jalepeno', 'chilli pepper', 'carrot', 'corn', 'cucumber']\n"
     ]
    }
   ],
   "source": [
    "# Crear instancia de DataPreparation\n",
    "data_prep = DataPreparation(data_dir=DATA_DIR, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_loader, val_loader, test_loader, num_classes, class_names = data_prep.create_dataloaders()\n",
    "\n",
    "print(\"\\n‚úÖ Datos cargados exitosamente!\")\n",
    "print(f\"   Clases: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3cb55a",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Paso 7: Crear Modelo\n",
    "\n",
    "Inicializamos el modelo ShuffleNet y lo movemos al dispositivo (GPU/CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f534a50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Cargando ShuffleNet V2 preentrenado...\n",
      "‚úÖ ShuffleNet V2 cargado exitosamente!\n",
      "‚ùÑÔ∏è  Congelando capas convolucionales (feature extractor)...\n",
      "‚úÖ Capas convolucionales congeladas!\n",
      "\n",
      "üéØ CLASIFICADOR SIMPLE (Versi√≥n 1) creado:\n",
      "   - Input features: 1024\n",
      "   - Output classes: 5\n",
      "   - Capas: 1 Linear\n",
      "   - BatchNorm: NO\n",
      "   - Dropout: NO\n",
      "\n",
      "============================================================\n",
      "üìä INFORMACI√ìN DEL MODELO\n",
      "============================================================\n",
      "Par√°metros totales:      1,258,729\n",
      "Par√°metros entrenables:  5,125\n",
      "Par√°metros congelados:   1,253,604\n",
      "Porcentaje entrenable:   0.41%\n",
      "============================================================\n",
      "\n",
      "‚úÖ Modelo movido a cpu\n"
     ]
    }
   ],
   "source": [
    "# Crear modelo\n",
    "model = ShuffleNetSimple(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    pretrained=True,\n",
    "    freeze_features=True\n",
    ")\n",
    "\n",
    "# Mostrar informaci√≥n del modelo\n",
    "model.print_model_info()\n",
    "\n",
    "# Mover modelo al dispositivo\n",
    "model = model.to(device)\n",
    "print(f\"\\n‚úÖ Modelo movido a {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93bb2b3",
   "metadata": {},
   "source": [
    "## üéØ Paso 8: Configurar Entrenamiento\n",
    "\n",
    "Definimos la funci√≥n de p√©rdida, optimizador y scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf6461ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loss function: CrossEntropyLoss\n",
      "‚úÖ Optimizer: Adam (lr=0.001)\n",
      "‚úÖ Scheduler: StepLR (step=5, gamma=0.1)\n"
     ]
    }
   ],
   "source": [
    "# Funci√≥n de p√©rdida\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(\"‚úÖ Loss function: CrossEntropyLoss\")\n",
    "\n",
    "# Optimizador (solo para par√°metros entrenables)\n",
    "optimizer = optim.Adam(model.get_trainable_params(), lr=LEARNING_RATE)\n",
    "print(f\"‚úÖ Optimizer: Adam (lr={LEARNING_RATE})\")\n",
    "\n",
    "# Scheduler (opcional - reduce LR cada 5 √©pocas)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "print(\"‚úÖ Scheduler: StepLR (step=5, gamma=0.1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91707939",
   "metadata": {},
   "source": [
    "## üîÑ Paso 9: Funciones de Entrenamiento y Validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "508d9091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funciones de entrenamiento y validaci√≥n definidas!\n"
     ]
    }
   ],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Entrena el modelo por una √©poca.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo a entrenar\n",
    "        train_loader: DataLoader de entrenamiento\n",
    "        criterion: Funci√≥n de p√©rdida\n",
    "        optimizer: Optimizador\n",
    "        device: Dispositivo (cuda/cpu)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (loss promedio, accuracy)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Progress bar\n",
    "    pbar = tqdm(train_loader, desc=\"Entrenando\", leave=False)\n",
    "    \n",
    "    for images, labels in pbar:\n",
    "        # Mover datos al dispositivo\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Estad√≠sticas\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Actualizar progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100 * correct / total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Valida el modelo.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo a validar\n",
    "        val_loader: DataLoader de validaci√≥n\n",
    "        criterion: Funci√≥n de p√©rdida\n",
    "        device: Dispositivo (cuda/cpu)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (loss promedio, accuracy)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            # Mover datos al dispositivo\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Estad√≠sticas\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "print(\"‚úÖ Funciones de entrenamiento y validaci√≥n definidas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a891457",
   "metadata": {},
   "source": [
    "## üöÄ Paso 10: Loop de Entrenamiento\n",
    "\n",
    "Entrenamos el modelo durante el n√∫mero de √©pocas especificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d07e816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ INICIANDO ENTRENAMIENTO\n",
      "======================================================================\n",
      "\n",
      "üìç √âpoca 1/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train Loss: 1.5965 | Train Acc: 37.90%\n",
      "‚úÖ Val Loss:   1.5655 | Val Acc:   63.83%\n",
      "üìä Learning Rate: 0.001000\n",
      "üåü ¬°Nuevo mejor modelo! Val Acc: 63.83%\n",
      "\n",
      "üìç √âpoca 2/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train Loss: 1.5600 | Train Acc: 50.68%\n",
      "‚úÖ Val Loss:   1.5243 | Val Acc:   68.09%\n",
      "üìä Learning Rate: 0.001000\n",
      "üåü ¬°Nuevo mejor modelo! Val Acc: 68.09%\n",
      "\n",
      "üìç √âpoca 3/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train Loss: 1.5275 | Train Acc: 61.42%\n",
      "‚úÖ Val Loss:   1.4857 | Val Acc:   82.98%\n",
      "üìä Learning Rate: 0.001000\n",
      "üåü ¬°Nuevo mejor modelo! Val Acc: 82.98%\n",
      "\n",
      "üìç √âpoca 4/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train Loss: 1.4971 | Train Acc: 68.26%\n",
      "‚úÖ Val Loss:   1.4507 | Val Acc:   87.23%\n",
      "üìä Learning Rate: 0.001000\n",
      "üåü ¬°Nuevo mejor modelo! Val Acc: 87.23%\n",
      "\n",
      "üìç √âpoca 5/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train Loss: 1.4696 | Train Acc: 73.97%\n",
      "‚úÖ Val Loss:   1.4194 | Val Acc:   89.36%\n",
      "üìä Learning Rate: 0.000100\n",
      "üåü ¬°Nuevo mejor modelo! Val Acc: 89.36%\n",
      "\n",
      "üìç √âpoca 6/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train Loss: 1.4514 | Train Acc: 77.40%\n",
      "‚úÖ Val Loss:   1.4163 | Val Acc:   89.36%\n",
      "üìä Learning Rate: 0.000100\n",
      "\n",
      "üìç √âpoca 7/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train Loss: 1.4515 | Train Acc: 76.26%\n",
      "‚úÖ Val Loss:   1.4154 | Val Acc:   89.36%\n",
      "üìä Learning Rate: 0.000100\n",
      "\n",
      "üìç √âpoca 8/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train Loss: 1.4440 | Train Acc: 79.91%\n",
      "‚úÖ Val Loss:   1.4113 | Val Acc:   87.23%\n",
      "üìä Learning Rate: 0.000100\n",
      "\n",
      "üìç √âpoca 9/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train Loss: 1.4460 | Train Acc: 75.80%\n",
      "‚úÖ Val Loss:   1.4089 | Val Acc:   89.36%\n",
      "üìä Learning Rate: 0.000100\n",
      "\n",
      "üìç √âpoca 10/10\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train Loss: 1.4396 | Train Acc: 79.68%\n",
      "‚úÖ Val Loss:   1.4044 | Val Acc:   89.36%\n",
      "üìä Learning Rate: 0.000010\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ENTRENAMIENTO COMPLETADO\n",
      "======================================================================\n",
      "üèÜ Mejor Val Accuracy: 89.36%\n",
      "‚úÖ Mejor modelo cargado para evaluaci√≥n\n"
     ]
    }
   ],
   "source": [
    "# Listas para guardar m√©tricas\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ INICIANDO ENTRENAMIENTO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nüìç √âpoca {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Entrenamiento\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "    \n",
    "    # Validaci√≥n\n",
    "    val_loss, val_acc = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # Guardar m√©tricas\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    # Actualizar learning rate\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Imprimir resultados\n",
    "    print(f\"‚úÖ Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"‚úÖ Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "    print(f\"üìä Learning Rate: {current_lr:.6f}\")\n",
    "    \n",
    "    # Guardar mejor modelo\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"üåü ¬°Nuevo mejor modelo! Val Acc: {best_val_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ ENTRENAMIENTO COMPLETADO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üèÜ Mejor Val Accuracy: {best_val_acc:.2f}%\")\n",
    "\n",
    "# Cargar el mejor modelo\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"‚úÖ Mejor modelo cargado para evaluaci√≥n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918862a0",
   "metadata": {},
   "source": [
    "## üìä Paso 11: Visualizar Curvas de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Gr√°fico de Loss\n",
    "axes[0].plot(train_losses, label='Train Loss', marker='o')\n",
    "axes[0].plot(val_losses, label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('√âpoca')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('P√©rdida durante el Entrenamiento')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Gr√°fico de Accuracy\n",
    "axes[1].plot(train_accs, label='Train Accuracy', marker='o')\n",
    "axes[1].plot(val_accs, label='Val Accuracy', marker='s')\n",
    "axes[1].set_xlabel('√âpoca')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Precisi√≥n durante el Entrenamiento')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Curvas de entrenamiento visualizadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ee43ce",
   "metadata": {},
   "source": [
    "## üß™ Paso 12: Evaluaci√≥n en el Conjunto de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf532eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üß™ EVALUACI√ìN EN TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Evaluar en test\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"\\n‚úÖ Test Loss: {test_loss:.4f}\")\n",
    "print(f\"‚úÖ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dee4309",
   "metadata": {},
   "source": [
    "## üìà Paso 13: Matriz de Confusi√≥n\n",
    "\n",
    "Visualizamos el desempe√±o del modelo en cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99aa47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Obtener predicciones en test set\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Crear matriz de confusi√≥n\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Visualizar matriz de confusi√≥n\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, \n",
    "            yticklabels=class_names)\n",
    "plt.xlabel('Predicci√≥n')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusi√≥n - Test Set')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Reporte de clasificaci√≥n\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä REPORTE DE CLASIFICACI√ìN\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(all_labels, all_preds, \n",
    "                          target_names=class_names, \n",
    "                          digits=4))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cebde03",
   "metadata": {},
   "source": [
    "## üíæ Paso 14: Guardar el Modelo\n",
    "\n",
    "Guardamos el modelo entrenado para uso futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0203b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo completo\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'train_accs': train_accs,\n",
    "    'val_losses': val_losses,\n",
    "    'val_accs': val_accs,\n",
    "    'test_acc': test_acc,\n",
    "    'test_loss': test_loss,\n",
    "    'class_names': class_names,\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'learning_rate': LEARNING_RATE\n",
    "}, 'shufflenet_modelo_final.pth')\n",
    "\n",
    "print(\"‚úÖ Modelo guardado como 'shufflenet_modelo_final.pth'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a62f6d6",
   "metadata": {},
   "source": [
    "## üéâ Paso 15: Resumen Final del Proyecto\n",
    "\n",
    "Mostramos un resumen completo de los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8899149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üéâ RESUMEN DEL PROYECTO SHUFFLENET - TRANSFER LEARNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüîµ CONFIGURACI√ìN:\")\n",
    "print(f\"   ‚Ä¢ Modelo base: ShuffleNet V2 x1.0 (ImageNet)\")\n",
    "print(f\"   ‚Ä¢ Clases: {NUM_CLASSES} vegetales\")\n",
    "print(f\"   ‚Ä¢ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   ‚Ä¢ Learning rate inicial: {LEARNING_RATE}\")\n",
    "print(f\"   ‚Ä¢ √âpocas: {NUM_EPOCHS}\")\n",
    "print(f\"   ‚Ä¢ Dispositivo: {device}\")\n",
    "\n",
    "print(\"\\nüîµ DATASET:\")\n",
    "print(f\"   ‚Ä¢ Clases: {', '.join(class_names)}\")\n",
    "print(f\"   ‚Ä¢ Train: {len(train_loader.dataset)} im√°genes\")\n",
    "print(f\"   ‚Ä¢ Validation: {len(val_loader.dataset)} im√°genes\")\n",
    "print(f\"   ‚Ä¢ Test: {len(test_loader.dataset)} im√°genes\")\n",
    "\n",
    "print(\"\\nüîµ ARQUITECTURA:\")\n",
    "params = model.count_parameters()\n",
    "print(f\"   ‚Ä¢ Par√°metros totales: {params['total']:,}\")\n",
    "print(f\"   ‚Ä¢ Par√°metros entrenables: {params['trainable']:,} ({params['trainable']/params['total']*100:.2f}%)\")\n",
    "print(f\"   ‚Ä¢ Feature extractor: Congelado\")\n",
    "print(f\"   ‚Ä¢ Clasificador: 1 capa FC (simple)\")\n",
    "\n",
    "print(\"\\nüîµ RESULTADOS FINALES:\")\n",
    "print(f\"   ‚Ä¢ Mejor Val Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "print(\"\\nüîµ ARCHIVOS GENERADOS:\")\n",
    "print(f\"   ‚Ä¢ Modelo guardado: shufflenet_modelo_final.pth\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ PROYECTO COMPLETADO EXITOSAMENTE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüí° PR√ìXIMOS PASOS:\")\n",
    "print(\"   1. Probar con diferentes hiperpar√°metros\")\n",
    "print(\"   2. Implementar clasificador m√°s complejo (BatchNorm, Dropout)\")\n",
    "print(\"   3. Hacer fine-tuning del feature extractor\")\n",
    "print(\"   4. Probar con m√°s √©pocas de entrenamiento\")\n",
    "print(\"   5. Experimentar con diferentes estrategias de data augmentation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
